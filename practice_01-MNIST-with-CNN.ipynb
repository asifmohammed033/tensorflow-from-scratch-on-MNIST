{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST with CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\",one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing weights with truncated normal distribution and returning them as variable\n",
    "def init_weights(shape):\n",
    "    init_random_dist = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(init_random_dist)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing biases with a constant and returning as a variable\n",
    "def init_bias(shape):\n",
    "    init_bias_vals = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(init_bias_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a 2D convolution wrapper using builtin conv2d from TF. From those docs:\n",
    "\n",
    "Computes a 2-D convolution given 4-D `input` and `filter` tensors.\n",
    "\n",
    "Given an input tensor of shape `[batch, in_height, in_width, in_channels]`\n",
    "and a filter / kernel tensor of shape\n",
    "`[filter_height, filter_width, in_channels, out_channels]`, this op\n",
    "performs the following:\n",
    "\n",
    "1. Flattens the filter to a 2-D matrix with shape\n",
    "   `[filter_height * filter_width * in_channels, output_channels]`.\n",
    "2. Extracts image patches from the input tensor to form a *virtual*\n",
    "   tensor of shape `[batch, out_height, out_width,\n",
    "   filter_height * filter_width * in_channels]`.\n",
    "3. For each patch, right-multiplies the filter matrix and the image patch\n",
    "   vector.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(x,W):\n",
    "    return tf.nn.conv2d(x,W, strides = [1, 1, 1, 1], padding= \"SAME\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a max pooling layer, again using built in TF functions:\n",
    "\n",
    "Performs the max pooling on the input.\n",
    "\n",
    "    Args:\n",
    "      value: A 4-D `Tensor` with shape `[batch, height, width, channels]` and\n",
    "        type `tf.float32`.\n",
    "      ksize: A list of ints that has length >= 4.  The size of the window for\n",
    "        each dimension of the input tensor.\n",
    "      strides: A list of ints that has length >= 4.  The stride of the sliding\n",
    "        window for each dimension of the input tensor.\n",
    "      padding: A string, either `'VALID'` or `'SAME'`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_pool_2by2(x):\n",
    "    return tf.nn.max_pool(x, ksize = [1, 2, 2, 1],\n",
    "                          strides = [1, 2, 2, 1],\n",
    "                          padding = 'SAME')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "creating a convolutional layer using conv2d function with ReLu activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolutional_layer(input_x, kernel_shape):\n",
    "    W = init_weights(kernel_shape)\n",
    "    b = init_bias([kernel_shape[3]])\n",
    "    return tf.nn.relu(conv2d(input_x, W)+b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "creating a dense layer with relu activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of neurons in this layer  = op_size\n",
    "def dense_layer(input_layer, op_size):\n",
    "    input_size = int(input_layer.get_shape()[1])\n",
    "    W = init_weights([input_size, op_size])\n",
    "    b = init_bias([op_size])\n",
    "    print(W.shape,b.shape)\n",
    "    return tf.matmul(input_layer,W) + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  placehlders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape = [None, 784])\n",
    "y_true = tf.placeholder(tf.float32, shape = [None, 10])\n",
    "rate1 = tf.placeholder(tf.float32) # for Dropout layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3136, 1024) (1024,)\n",
      "(1024, 10) (10,)\n"
     ]
    }
   ],
   "source": [
    "# input layer\n",
    "x_image = tf.reshape(x, [-1,28,28,1])\n",
    "\n",
    "\n",
    "# convo_1, using 5x5x1 filter, and 32 such filters\n",
    "convo_1 = convolutional_layer(x_image, kernel_shape = [6, 6, 1, 32])\n",
    "convo_1_pooling = max_pool_2by2(convo_1)\n",
    "# size of output of this layer is [-1,14,14,32]\n",
    "\n",
    "\n",
    "# convo_2, using 5x5x32 filter, and 64 such filters \n",
    "convo_2 = convolutional_layer(convo_1_pooling, kernel_shape = [6,6,32,64])\n",
    "convo_2_pooling = max_pool_2by2(convo_2)\n",
    "# size of output of this layer is [-1, 7, 7, 64]\n",
    "\n",
    "# flattening and applying a fully connected layer with 1024 neurons\n",
    "convo_2_flat = tf.reshape(convo_2_pooling, [-1,7*7*64])\n",
    "full_layer_1 = tf.nn.relu(dense_layer(convo_2_flat, 1024))\n",
    "# size of output of this layer is [-1,1024]\n",
    "\n",
    "\n",
    "# Including Dropouts\n",
    "full_layer_1_dropout = tf.nn.dropout(full_layer_1, rate = 0.5)\n",
    "\n",
    "# dense layer2 with 10 neurons\n",
    "y_pred = dense_layer(full_layer_1_dropout, 10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels = y_true , logits = y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.0001)\n",
    "train = optimizer.minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  initialize variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current step = 0\n",
      "Accuacy :: 0.0929\n",
      "\n",
      "\n",
      "Current step = 50\n",
      "Accuacy :: 0.5414\n",
      "\n",
      "\n",
      "Current step = 100\n",
      "Accuacy :: 0.738\n",
      "\n",
      "\n",
      "Current step = 150\n",
      "Accuacy :: 0.8008\n",
      "\n",
      "\n",
      "Current step = 200\n",
      "Accuacy :: 0.8407\n",
      "\n",
      "\n",
      "Current step = 250\n",
      "Accuacy :: 0.8635\n",
      "\n",
      "\n",
      "Current step = 300\n",
      "Accuacy :: 0.8845\n",
      "\n",
      "\n",
      "Current step = 350\n",
      "Accuacy :: 0.896\n",
      "\n",
      "\n",
      "Current step = 400\n",
      "Accuacy :: 0.9057\n",
      "\n",
      "\n",
      "Current step = 450\n",
      "Accuacy :: 0.9145\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "steps = 500\n",
    "accuracy1 = []\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    \n",
    "    for i in range(steps):\n",
    "        x_batch, y_batch = mnist.train.next_batch(100)\n",
    "        feed = {x: x_batch,\n",
    "               y_true: y_batch, \n",
    "               rate1 : 0.5}\n",
    "        sess.run(train, feed_dict= feed)\n",
    "        \n",
    "        \n",
    "        if i%50 == 0:\n",
    "            print('Current step = {}'.format(i))\n",
    "            \n",
    "            matches = tf.equal(tf.argmax(y_pred,1),tf.argmax(y_true,1))\n",
    "            acc = tf.reduce_mean(tf.cast(matches,  tf.float32))\n",
    "            accuracy = sess.run(acc, feed_dict = {x: mnist.test.images,\n",
    "                                             y_true: mnist.test.labels,\n",
    "                                             rate1: 1.0})\n",
    "            print('Accuacy ::',accuracy)\n",
    "            accuracy1.append(accuracy)\n",
    "            \n",
    "            print('\\n')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
